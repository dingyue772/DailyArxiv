---
title: Latest 5 Papers - February 04, 2026
labels: documentation
---
**Please check the [Github](https://github.com/dingyue772/DailyArxiv) page for a better reading experience and more papers.**

## omni
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[GuardReasoner-Omni: A Reasoning-based Multi-modal Guardrail for Text, Image, and Video](https://arxiv.org/abs/2602.03328v1)** | 2026-02-03 |  |
| **[vLLM-Omni: Fully Disaggregated Serving for Any-to-Any Multimodal Models](https://arxiv.org/abs/2602.02204v1)** | 2026-02-02 | 12 pages, 8 figures |
| **[Omni-Judge: Can Omni-LLMs Serve as Human-Aligned Judges for Text-Conditioned Audio-Video Generation?](https://arxiv.org/abs/2602.01623v1)** | 2026-02-02 |  |
| **[Omni-RRM: Advancing Omni Reward Modeling via Automatic Rubric-Grounded Preference Synthesis](https://arxiv.org/abs/2602.00846v1)** | 2026-01-31 |  |
| **[Omni-fMRI: A Universal Atlas-Free fMRI Foundation Model](https://arxiv.org/abs/2601.23090v1)** | 2026-01-30 |  |

## video
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[PrevizWhiz: Combining Rough 3D Scenes and 2D Video to Guide Generative Video Previsualization](https://arxiv.org/abs/2602.03838v1)** | 2026-02-03 | <details><summary>21 pa...</summary><p>21 pages, 13 figures; accepted and to appear at CHI 2026</p></details> |
| **[3D-Aware Implicit Motion Control for View-Adaptive Human Video Generation](https://arxiv.org/abs/2602.03796v1)** | 2026-02-03 | <details><summary>Proje...</summary><p>Project Page: https://hjrphoebus.github.io/3DiMo/</p></details> |
| **[BridgeV2W: Bridging Video Generation Models to Embodied World Models via Embodiment Masks](https://arxiv.org/abs/2602.03793v1)** | 2026-02-03 |  |
| **[LIVE: Long-horizon Interactive Video World Modeling](https://arxiv.org/abs/2602.03747v1)** | 2026-02-03 | 18 pages, 22 figures |
| **[OmniRAG-Agent: Agentic Omnimodal Reasoning for Low-Resource Long Audio-Video Question Answering](https://arxiv.org/abs/2602.03707v1)** | 2026-02-03 |  |

