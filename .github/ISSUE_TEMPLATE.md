---
title: Latest 5 Papers - March 18, 2025
labels: documentation
---
**Please check the [Github](https://github.com/dingyue772/DailyArxiv) page for a better reading experience and more papers.**

## Hallucination
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Graph-Grounded LLMs: Leveraging Graphical Function Calling to Minimize LLM Hallucinations](http://arxiv.org/abs/2503.10941v1)** | 2025-03-13 |  |
| **[HALURust: Exploiting Hallucinations of Large Language Models to Detect Vulnerabilities in Rust](http://arxiv.org/abs/2503.10793v1)** | 2025-03-13 |  |
| **[TruthPrInt: Mitigating LVLM Object Hallucination Via Latent Truthful-Guided Pre-Intervention](http://arxiv.org/abs/2503.10602v1)** | 2025-03-13 | <details><summary>15 pa...</summary><p>15 pages, 9 figures, the first two authors contributed equally</p></details> |
| **[Through the Magnifying Glass: Adaptive Perception Magnification for Hallucination-Free VLM Decoding](http://arxiv.org/abs/2503.10183v2)** | 2025-03-14 | <details><summary>19 pa...</summary><p>19 pages, 5 figures, 9 tables</p></details> |
| **[Is LLMs Hallucination Usable? LLM-based Negative Reasoning for Fake News Detection](http://arxiv.org/abs/2503.09153v1)** | 2025-03-12 | <details><summary>9 pag...</summary><p>9 pages, 12 figures, conference</p></details> |

## MLLM
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[CINEMA: Coherent Multi-Subject Video Generation via MLLM-Based Guidance](http://arxiv.org/abs/2503.10391v1)** | 2025-03-13 |  |
| **[LVAgent: Long Video Understanding by Multi-Round Dynamical Collaboration of MLLM Agents](http://arxiv.org/abs/2503.10200v1)** | 2025-03-13 |  |
| **[Information Density Principle for MLLM Benchmarks](http://arxiv.org/abs/2503.10079v1)** | 2025-03-13 |  |
| **[UVE: Are MLLMs Unified Evaluators for AI-Generated Videos?](http://arxiv.org/abs/2503.09949v1)** | 2025-03-13 |  |
| **[Exo2Ego: Exocentric Knowledge Guided MLLM for Egocentric Video Understanding](http://arxiv.org/abs/2503.09143v1)** | 2025-03-12 | <details><summary>Proje...</summary><p>Project: https://egovisiongroup.github.io/Exo2Ego.github.io/</p></details> |

## Reasoning
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Neutralizing Bias in LLM Reasoning using Entailment Graphs](http://arxiv.org/abs/2503.11614v1)** | 2025-03-14 | 17 pages, 7 figures |
| **[Implicit Bias-Like Patterns in Reasoning Models](http://arxiv.org/abs/2503.11572v1)** | 2025-03-14 |  |
| **[VERIFY: A Benchmark of Visual Explanation and Reasoning for Investigating Multimodal Reasoning Fidelity](http://arxiv.org/abs/2503.11557v1)** | 2025-03-14 |  |
| **[V-STaR: Benchmarking Video-LLMs on Video Spatio-Temporal Reasoning](http://arxiv.org/abs/2503.11495v1)** | 2025-03-14 | <details><summary>A ben...</summary><p>A benchmark for Video Spatio-Temporal Reasoning</p></details> |
| **[RESPONSE: Benchmarking the Ability of Language Models to Undertake Commonsense Reasoning in Crisis Situation](http://arxiv.org/abs/2503.11348v1)** | 2025-03-14 |  |

## Reward Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Statistical Impossibility and Possibility of Aligning LLMs with Human Preferences: From Condorcet Paradox to Nash Equilibrium](http://arxiv.org/abs/2503.10990v1)** | 2025-03-14 |  |
| **[Auditing language models for hidden objectives](http://arxiv.org/abs/2503.10965v1)** | 2025-03-14 |  |
| **[VisualPRM: An Effective Process Reward Model for Multimodal Reasoning](http://arxiv.org/abs/2503.10291v1)** | 2025-03-13 |  |
| **[Policy Teaching via Data Poisoning in Learning from Human Preferences](http://arxiv.org/abs/2503.10228v1)** | 2025-03-13 | In AISTATS 2025 |
| **[Representation-based Reward Modeling for Efficient Safety Alignment of Large Language Model](http://arxiv.org/abs/2503.10093v1)** | 2025-03-13 |  |

