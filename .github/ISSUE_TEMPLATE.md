---
title: Latest 5 Papers - November 21, 2025
labels: documentation
---
**Please check the [Github](https://github.com/dingyue772/DailyArxiv) page for a better reading experience and more papers.**

## Hallucination
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SeSE: A Structural Information-Guided Uncertainty Quantification Framework for Hallucination Detection in LLMs](https://arxiv.org/abs/2511.16275v1)** | 2025-11-20 | <details><summary>14 pa...</summary><p>14 pages of main text and 10 pages of appendices</p></details> |
| **[Thinking, Faithful and Stable: Mitigating Hallucinations in LLMs](https://arxiv.org/abs/2511.15921v1)** | 2025-11-19 | <details><summary>Origi...</summary><p>Originally released June 5, 2025</p></details> |
| **[Mathematical Analysis of Hallucination Dynamics in Large Language Models: Uncertainty Quantification, Advanced Decoding, and Principled Mitigation](https://arxiv.org/abs/2511.15005v1)** | 2025-11-19 | <details><summary>10 pa...</summary><p>10 pages, theoretical/mathematical LLM research, no figures, intended for peer-reviewed journal</p></details> |
| **[Listen Like a Teacher: Mitigating Whisper Hallucinations using Adaptive Layer Attention and Knowledge Distillation](https://arxiv.org/abs/2511.14219v1)** | 2025-11-18 | <details><summary>Accep...</summary><p>Accepted at AAAI 2026 - Main Technical Track</p></details> |
| **[SymLoc: Symbolic Localization of Hallucination across HaluEval and TruthfulQA](https://arxiv.org/abs/2511.14172v1)** | 2025-11-18 |  |

## Safety
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Synthesis of Safety Specifications for Probabilistic Systems](https://arxiv.org/abs/2511.16579v1)** | 2025-11-20 | 23 pages |
| **[SafeRBench: A Comprehensive Benchmark for Safety Assessment in Large Reasoning Models](https://arxiv.org/abs/2511.15169v2)** | 2025-11-20 | 30 pages, 8 figures |
| **[Is Your VLM for Autonomous Driving Safety-Ready? A Comprehensive Benchmark for Evaluating External and In-Cabin Risks](https://arxiv.org/abs/2511.14592v2)** | 2025-11-19 |  |
| **[Operationalizing Pluralistic Values in Large Language Model Alignment Reveals Trade-offs in Safety, Inclusivity, and Model Behavior](https://arxiv.org/abs/2511.14476v1)** | 2025-11-18 |  |
| **[Safe-ROS: An Architecture for Autonomous Robots in Safety-Critical Domains](https://arxiv.org/abs/2511.14433v1)** | 2025-11-18 | <details><summary>In Pr...</summary><p>In Proceedings FMAS 2025, arXiv:2511.13245</p></details> |

