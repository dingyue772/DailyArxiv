---
title: Latest 5 Papers - October 30, 2025
labels: documentation
---
**Please check the [Github](https://github.com/dingyue772/DailyArxiv) page for a better reading experience and more papers.**

## Hallucination
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Mitigating Hallucination in Large Language Models (LLMs): An Application-Oriented Survey on RAG, Reasoning, and Agentic Systems](http://arxiv.org/abs/2510.24476v1)** | 2025-10-28 | <details><summary>25 pa...</summary><p>25 pages, 7 figures, 3 tables</p></details> |
| **[HACK: Hallucinations Along Certainty and Knowledge Axes](http://arxiv.org/abs/2510.24222v1)** | 2025-10-28 | <details><summary>The c...</summary><p>The code is available at https://github.com/technion-cs-nlp/HACK_Hallucinations_Along_Certainty_and_Knowledge_axes</p></details> |
| **[Challenging Multilingual LLMs: A New Taxonomy and Benchmark for Unraveling Hallucination in Translation](http://arxiv.org/abs/2510.24073v1)** | 2025-10-28 |  |
| **[The Reasoning Trap: How Enhancing LLM Reasoning Amplifies Tool Hallucination](http://arxiv.org/abs/2510.22977v1)** | 2025-10-27 | 18 pages, 5 figures |
| **[Multi-Modal Fact-Verification Framework for Reducing Hallucinations in Large Language Models](http://arxiv.org/abs/2510.22751v1)** | 2025-10-26 |  |

## Safety
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid Validation in Realistic Workflows](http://arxiv.org/abs/2510.24411v1)** | 2025-10-28 | work in progress |
| **[Advancing Interdisciplinary Approaches to Online Safety Research](http://arxiv.org/abs/2510.24227v1)** | 2025-10-28 |  |
| **[Linear effects, exceptions, and resource safety: a Curry-Howard correspondence for destructors](http://arxiv.org/abs/2510.23517v1)** | 2025-10-27 | 26 pages + appendix |
| **[An Error-Based Safety Buffer for Safe Adaptive Control (Extended Version)](http://arxiv.org/abs/2510.23491v1)** | 2025-10-27 | <details><summary>Submi...</summary><p>Submitted to IEEE Transactions on Automatic Control</p></details> |
| **[Guardian: Decoupling Exploration from Safety in Reinforcement Learning](http://arxiv.org/abs/2510.22859v1)** | 2025-10-26 |  |

