---
title: Latest 5 Papers - October 28, 2025
labels: documentation
---
**Please check the [Github](https://github.com/dingyue772/DailyArxiv) page for a better reading experience and more papers.**

## Hallucination
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[InterpDetect: Interpretable Signals for Detecting Hallucinations in Retrieval-Augmented Generation](http://arxiv.org/abs/2510.21538v1)** | 2025-10-24 |  |
| **[Reasoning's Razor: Reasoning Improves Accuracy but Can Hurt Recall at Critical Operating Points in Safety and Hallucination Detection](http://arxiv.org/abs/2510.21049v1)** | 2025-10-23 |  |
| **[Neural Diversity Regularizes Hallucinations in Small Models](http://arxiv.org/abs/2510.20690v1)** | 2025-10-23 |  |
| **[The Impact of Negated Text on Hallucination with Large Language Models](http://arxiv.org/abs/2510.20375v1)** | 2025-10-23 | <details><summary>Accep...</summary><p>Accepted to the EMNLP 2025</p></details> |
| **[Why LVLMs Are More Prone to Hallucinations in Longer Responses: The Role of Context](http://arxiv.org/abs/2510.20229v1)** | 2025-10-23 |  |

## Safety
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Auction-Based Responsibility Allocation for Scalable Decentralized Safety Filters in Cooperative Multi-Agent Collision Avoidance](http://arxiv.org/abs/2510.21546v1)** | 2025-10-24 | <details><summary>6 pag...</summary><p>6 pages, 3 figures, Submitted to Control Engineering Practice and IFAC World Congress 2026</p></details> |
| **[When Models Outthink Their Safety: Mitigating Self-Jailbreak in Large Reasoning Models with Chain-of-Guardrails](http://arxiv.org/abs/2510.21285v1)** | 2025-10-24 | <details><summary>First...</summary><p>First two authors contributed equally. The main text is 10 pages, with an appendix of 19 pages. The paper contains 18 figures and 16 tables</p></details> |
| **[Kriging measure-valued data with sparse observations: application to nuclear safety studies](http://arxiv.org/abs/2510.21277v1)** | 2025-10-24 |  |
| **[Out-of-Distribution Detection for Safety Assurance of AI and Autonomous Systems](http://arxiv.org/abs/2510.21254v1)** | 2025-10-24 |  |
| **[SafetyPairs: Isolating Safety Critical Image Features with Counterfactual Image Generation](http://arxiv.org/abs/2510.21120v1)** | 2025-10-24 |  |

