---
title: Latest 5 Papers - October 23, 2025
labels: documentation
---
**Please check the [Github](https://github.com/dingyue772/DailyArxiv) page for a better reading experience and more papers.**

## Hallucination
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Grounding or Guessing? Visual Signals for Detecting Hallucinations in Sign Language Translation](http://arxiv.org/abs/2510.18439v1)** | 2025-10-21 |  |
| **[Beyond Single Models: Mitigating Multimodal Hallucinations via Adaptive Token Ensemble Decoding](http://arxiv.org/abs/2510.18321v1)** | 2025-10-21 |  |
| **[Train for Truth, Keep the Skills: Binary Retrieval-Augmented Reward Mitigates Hallucinations](http://arxiv.org/abs/2510.17733v1)** | 2025-10-20 |  |
| **[Wisdom is Knowing What not to Say: Hallucination-Free LLMs Unlearning via Attention Shifting](http://arxiv.org/abs/2510.17210v1)** | 2025-10-20 | 22 pages, 10 figures |
| **[SHIELD: Suppressing Hallucinations In LVLM Encoders via Bias and Vulnerability Defense](http://arxiv.org/abs/2510.16596v1)** | 2025-10-18 |  |

## Safety
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Safe But Not Sorry: Reducing Over-Conservatism in Safety Critics via Uncertainty-Aware Modulation](http://arxiv.org/abs/2510.18478v1)** | 2025-10-21 |  |
| **[Engagement Undermines Safety: How Stereotypes and Toxicity Shape Humor in Language Models](http://arxiv.org/abs/2510.18454v1)** | 2025-10-21 |  |
| **[VLSU: Mapping the Limits of Joint Multimodal Understanding for AI Safety](http://arxiv.org/abs/2510.18214v1)** | 2025-10-21 | <details><summary>10 pa...</summary><p>10 pages, 5 figures, 4 tables. Under review</p></details> |
| **[Annotating the Chain-of-Thought: A Behavior-Labeled Dataset for AI Safety](http://arxiv.org/abs/2510.18154v1)** | 2025-10-20 |  |
| **[SafeCoop: Unravelling Full Stack Safety in Agentic Collaborative Driving](http://arxiv.org/abs/2510.18123v1)** | 2025-10-20 |  |

