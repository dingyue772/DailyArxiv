---
title: Latest 5 Papers - May 19, 2025
labels: documentation
---
**Please check the [Github](https://github.com/dingyue772/DailyArxiv) page for a better reading experience and more papers.**

## Reward Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[HelpSteer3-Preference: Open Human-Annotated Preference Data across Diverse Tasks and Languages](http://arxiv.org/abs/2505.11475v1)** | 2025-05-16 | 38 pages, 2 figures |
| **[Is PRM Necessary? Problem-Solving RL Implicitly Induces PRM Capability in LLMs](http://arxiv.org/abs/2505.11227v1)** | 2025-05-16 |  |
| **[BLEUBERI: BLEU is a surprisingly effective reward for instruction following](http://arxiv.org/abs/2505.11080v1)** | 2025-05-16 | <details><summary>28 pa...</summary><p>28 pages, 11 figures, 15 tables</p></details> |
| **[ReWiND: Language-Guided Rewards Teach Robot Policies without New Demonstrations](http://arxiv.org/abs/2505.10911v1)** | 2025-05-16 |  |
| **[A Systematic Analysis of Base Model Choice for Reward Modeling](http://arxiv.org/abs/2505.10775v1)** | 2025-05-16 | <details><summary>19 pa...</summary><p>19 pages, 13 figures, 5 tables</p></details> |

## Reasoning
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SoftCoT++: Test-Time Scaling with Soft Chain-of-Thought Reasoning](http://arxiv.org/abs/2505.11484v1)** | 2025-05-16 | 14 pages |
| **[Disentangling Reasoning and Knowledge in Medical Large Language Models](http://arxiv.org/abs/2505.11462v1)** | 2025-05-16 |  |
| **[When Thinking Fails: The Pitfalls of Reasoning for Instruction-Following in LLMs](http://arxiv.org/abs/2505.11423v1)** | 2025-05-16 |  |
| **[Patho-R1: A Multimodal Reinforcement Learning-Based Pathology Expert Reasoner](http://arxiv.org/abs/2505.11404v1)** | 2025-05-16 |  |
| **[Benchmarking Critical Questions Generation: A Challenging Reasoning Task for Large Language Models](http://arxiv.org/abs/2505.11341v1)** | 2025-05-16 |  |

