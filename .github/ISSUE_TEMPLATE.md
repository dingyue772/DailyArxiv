---
title: Latest 5 Papers - November 28, 2025
labels: documentation
---
**Please check the [Github](https://github.com/dingyue772/DailyArxiv) page for a better reading experience and more papers.**

## Hallucination
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Tell Model Where to Look: Mitigating Hallucinations in MLLMs by Vision-Guided Attention](https://arxiv.org/abs/2511.20032v1)** | 2025-11-25 | Under Review |
| **[Alternating Perception-Reasoning for Hallucination-Resistant Video Understanding](https://arxiv.org/abs/2511.18463v2)** | 2025-11-25 | 32 pages, 36 figures |
| **["AGI" team at SHROOM-CAP: Data-Centric Approach to Multilingual Hallucination Detection using XLM-RoBERTa](https://arxiv.org/abs/2511.18301v1)** | 2025-11-23 | <details><summary>Accep...</summary><p>Accepted to the 1st Workshop on Confabulation, Hallucinations & Overgeneration in Multilingual and Practical Settings (CHOMPS) at AACL-IJCNLP 2025</p></details> |
| **[Measuring the Impact of Lexical Training Data Coverage on Hallucination Detection in Large Language Models](https://arxiv.org/abs/2511.17946v1)** | 2025-11-22 |  |
| **[Intervene-All-Paths: Unified Mitigation of LVLM Hallucinations across Alignment Formats](https://arxiv.org/abs/2511.17254v1)** | 2025-11-21 | <details><summary>Accep...</summary><p>Accepted to NeurIPS 2025, Project Page: https://github.com/SooLab/AllPath</p></details> |

## Safety
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Predictive Safety Shield for Dyna-Q Reinforcement Learning](https://arxiv.org/abs/2511.21531v1)** | 2025-11-26 |  |
| **[Self-Guided Defense: Adaptive Safety Alignment for Reasoning Models via Synthesized Guidelines](https://arxiv.org/abs/2511.21214v1)** | 2025-11-26 |  |
| **[Breaking the Safety-Capability Tradeoff: Reinforcement Learning with Verifiable Rewards Maintains Safety Guardrails in LLMs](https://arxiv.org/abs/2511.21050v1)** | 2025-11-26 | <details><summary>AAAI-...</summary><p>AAAI-26 Workshop on Post-AI Formal Methods</p></details> |
| **[GuardTrace-VL: Detecting Unsafe Multimodel Reasoning via Iterative Safety Supervision](https://arxiv.org/abs/2511.20994v1)** | 2025-11-26 |  |
| **[Conformal Safety Monitoring for Flight Testing: A Case Study in Data-Driven Safety Learning](https://arxiv.org/abs/2511.20811v1)** | 2025-11-25 | <details><summary>ICRA ...</summary><p>ICRA 2025 Workshop on Robot safety under uncertainty from intangible specifications</p></details> |

