---
title: Latest 5 Papers - September 23, 2025
labels: documentation
---
**Please check the [Github](https://github.com/dingyue772/DailyArxiv) page for a better reading experience and more papers.**

## Hallucination
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[EigenTrack: Spectral Activation Feature Tracking for Hallucination and Out-of-Distribution Detection in LLMs and VLMs](http://arxiv.org/abs/2509.15735v1)** | 2025-09-19 | <details><summary>5 pag...</summary><p>5 pages, submitted to ICASSP 2026, September 2025</p></details> |
| **[ORCA: Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models](http://arxiv.org/abs/2509.15435v1)** | 2025-09-18 |  |
| **[Knowledge-Driven Hallucination in Large Language Models: An Empirical Study on Process Modeling](http://arxiv.org/abs/2509.15336v1)** | 2025-09-18 | <details><summary>The V...</summary><p>The Version of Record of this contribution will be published in the proceedings of the 2nd International Workshop on Generative AI for Process Mining (GenAI4PM 2025). This preprint has not undergone peer review or any post-submission improvements or corrections</p></details> |
| **[Diving into Mitigating Hallucinations from a Vision Perspective for Large Vision-Language Models](http://arxiv.org/abs/2509.13836v1)** | 2025-09-17 | <details><summary>Accep...</summary><p>Accepted by EMNLP2025 Finding</p></details> |
| **[Geometric Uncertainty for Detecting and Correcting Hallucinations in LLMs](http://arxiv.org/abs/2509.13813v1)** | 2025-09-17 |  |

## Safety
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SABER: Uncovering Vulnerabilities in Safety Alignment via Cross-Layer Residual Connection](http://arxiv.org/abs/2509.16060v1)** | 2025-09-19 | <details><summary>Accep...</summary><p>Accepted in EMNLP'25 Main</p></details> |
| **[Learning Safety for Obstacle Avoidance via Control Barrier Functions](http://arxiv.org/abs/2509.16037v1)** | 2025-09-19 | 9 pages, 6 figures |
| **[Beyond Surface Alignment: Rebuilding LLMs Safety Mechanism via Probabilistically Ablating Refusal Direction](http://arxiv.org/abs/2509.15202v1)** | 2025-09-18 | <details><summary>Accep...</summary><p>Accepted by EMNLP2025 Finding</p></details> |
| **[Designing Latent Safety Filters using Pre-Trained Vision Models](http://arxiv.org/abs/2509.14758v1)** | 2025-09-18 |  |
| **[Toxicity Red-Teaming: Benchmarking LLM Safety in Singapore's Low-Resource Languages](http://arxiv.org/abs/2509.15260v1)** | 2025-09-18 | 9 pages, EMNLP 2025 |

