---
title: Latest 5 Papers - June 06, 2025
labels: documentation
---
**Please check the [Github](https://github.com/dingyue772/DailyArxiv) page for a better reading experience and more papers.**

## Reward Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Guided Speculative Inference for Efficient Test-Time Alignment of LLMs](http://arxiv.org/abs/2506.04118v1)** | 2025-06-04 | 12 pages, 2 figures |
| **[Crowd-SFT: Crowdsourcing for LLM Alignment](http://arxiv.org/abs/2506.04063v1)** | 2025-06-04 |  |
| **[RewardAnything: Generalizable Principle-Following Reward Models](http://arxiv.org/abs/2506.03637v1)** | 2025-06-04 | 23 pages, 8 figures |
| **[ControlThinker: Unveiling Latent Semantics for Controllable Image Generation through Visual Reasoning](http://arxiv.org/abs/2506.03596v1)** | 2025-06-04 |  |
| **[FreePRM: Training Process Reward Models Without Ground Truth Process Labels](http://arxiv.org/abs/2506.03570v1)** | 2025-06-04 |  |

## Reasoning
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Struct2D: A Perception-Guided Framework for Spatial Reasoning in Large Multimodal Models](http://arxiv.org/abs/2506.04220v1)** | 2025-06-04 | <details><summary>https...</summary><p>https://github.com/neu-vi/struct2d</p></details> |
| **[Does Thinking More always Help? Understanding Test-Time Scaling in Reasoning Models](http://arxiv.org/abs/2506.04210v1)** | 2025-06-04 |  |
| **[Advancing Multimodal Reasoning: From Optimized Cold Start to Staged Reinforcement Learning](http://arxiv.org/abs/2506.04207v1)** | 2025-06-04 | 19 pages, 6 figures |
| **[EPiC: Towards Lossless Speedup for Reasoning Training through Edge-Preserving CoT Condensation](http://arxiv.org/abs/2506.04205v1)** | 2025-06-04 |  |
| **[R-Search: Empowering LLM Reasoning with Search via Multi-Reward Reinforcement Learning](http://arxiv.org/abs/2506.04185v1)** | 2025-06-04 | 16 pages, 3 figures |

