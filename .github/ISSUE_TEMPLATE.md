---
title: Latest 5 Papers - October 14, 2025
labels: documentation
---
**Please check the [Github](https://github.com/dingyue772/DailyArxiv) page for a better reading experience and more papers.**

## Hallucination
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Hallucination Filtering in Radiology Vision-Language Models Using Discrete Semantic Entropy](http://arxiv.org/abs/2510.09256v1)** | 2025-10-10 | <details><summary>Code ...</summary><p>Code is available: https://github.com/TruhnLab/VisionSemanticEntropy</p></details> |
| **[On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large Vision-Language Models](http://arxiv.org/abs/2510.09008v1)** | 2025-10-10 |  |
| **[Revisiting Hallucination Detection with Effective Rank-based Uncertainty](http://arxiv.org/abs/2510.08389v1)** | 2025-10-09 |  |
| **[Detecting and Mitigating Insertion Hallucination in Video-to-Audio Generation](http://arxiv.org/abs/2510.08078v2)** | 2025-10-13 |  |
| **[The Unintended Trade-off of AI Alignment:Balancing Hallucination Mitigation and Safety in LLMs](http://arxiv.org/abs/2510.07775v1)** | 2025-10-09 |  |

## Safety
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Safety Game: Balancing Safe and Informative Conversations with Blackbox Agentic AI using LP Solvers](http://arxiv.org/abs/2510.09330v1)** | 2025-10-10 |  |
| **[Safety Analysis of eVTOL Operations based on STPA](http://arxiv.org/abs/2510.09283v1)** | 2025-10-10 |  |
| **[Decoupling Safety into Orthogonal Subspace: Cost-Efficient and Performance-Preserving Alignment for Large Language Models](http://arxiv.org/abs/2510.09004v1)** | 2025-10-10 | Work in Progress |
| **[The Alignment Waltz: Jointly Training Agents to Collaborate for Safety](http://arxiv.org/abs/2510.08240v1)** | 2025-10-09 |  |
| **[The Unintended Trade-off of AI Alignment:Balancing Hallucination Mitigation and Safety in LLMs](http://arxiv.org/abs/2510.07775v1)** | 2025-10-09 |  |

