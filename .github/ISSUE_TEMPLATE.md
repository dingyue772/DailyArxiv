---
title: Latest 5 Papers - September 24, 2025
labels: documentation
---
**Please check the [Github](https://github.com/dingyue772/DailyArxiv) page for a better reading experience and more papers.**

## Hallucination
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Turk-LettuceDetect: A Hallucination Detection Models for Turkish RAG Applications](http://arxiv.org/abs/2509.17671v1)** | 2025-09-22 |  |
| **[ChartHal: A Fine-grained Framework Evaluating Hallucination of Large Vision Language Models in Chart Understanding](http://arxiv.org/abs/2509.17481v1)** | 2025-09-22 |  |
| **[Semantic Reformulation Entropy for Robust Hallucination Detection in QA Tasks](http://arxiv.org/abs/2509.17445v1)** | 2025-09-22 | <details><summary>5page...</summary><p>5pages, 5 figures, submit to ICASSP 2026</p></details> |
| **[Enhancing Financial RAG with Agentic AI and Multi-HyDE: A Novel Approach to Knowledge Retrieval and Hallucination Reduction](http://arxiv.org/abs/2509.16369v1)** | 2025-09-19 | <details><summary>14 Pa...</summary><p>14 Pages, 8 Tables, 2 Figures. Accepted and to be published in the proceedings of FinNLP, Empirical Methods in Natural Language Processing 2025</p></details> |
| **[How Large Language Models are Designed to Hallucinate](http://arxiv.org/abs/2509.16297v1)** | 2025-09-19 | <details><summary>23 pa...</summary><p>23 pages, 2 tables, 2 figures</p></details> |

## Safety
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Strategic Dishonesty Can Undermine AI Safety Evaluations of Frontier LLMs](http://arxiv.org/abs/2509.18058v2)** | 2025-09-23 |  |
| **[DriveDPO: Policy Learning via Safety DPO For End-to-End Autonomous Driving](http://arxiv.org/abs/2509.17940v1)** | 2025-09-22 | NeurIPS 2025 |
| **[EigenSafe: A Spectral Framework for Learning-Based Stochastic Safety Filtering](http://arxiv.org/abs/2509.17750v1)** | 2025-09-22 | <details><summary>Works...</summary><p>Workshop on Safe and Robust Robot Learning for Operation in the Real World (SAFE-ROL) at CoRL 2025</p></details> |
| **[Distributionally Robust Safety Verification of Neural Networks via Worst-Case CVaR](http://arxiv.org/abs/2509.17413v1)** | 2025-09-22 |  |
| **[The SAGES Critical View of Safety Challenge: A Global Benchmark for AI-Assisted Surgical Quality Assessment](http://arxiv.org/abs/2509.17100v1)** | 2025-09-21 | 18 pages, 10 figures |

