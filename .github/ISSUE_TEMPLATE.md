---
title: Latest 5 Papers - November 14, 2025
labels: documentation
---
**Please check the [Github](https://github.com/dingyue772/DailyArxiv) page for a better reading experience and more papers.**

## Hallucination
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Hallucination Detection and Hallucination Mitigation: An Investigation](https://arxiv.org/pdf/2401.08358v1)** | 2024-01-17 |  |
| **[Code Hallucination](https://arxiv.org/pdf/2407.04831v2)** | 2024-08-09 |  |
| **[Stop learning it all to mitigate visual hallucination, Focus on the hallucination target](https://arxiv.org/pdf/2506.11417v1)** | 2025-06-16 | <details><summary>Accep...</summary><p>Accepted to CVPR 2025</p></details> |
| **[Removal of Hallucination on Hallucination: Debate-Augmented RAG](https://arxiv.org/pdf/2505.18581v1)** | 2025-05-27 | Accepted by ACL 2025 |
| **[LightHouse: A Survey of AGI Hallucination](https://arxiv.org/pdf/2401.06792v2)** | 2024-01-18 |  |

## Safety
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SAFETY-J: Evaluating Safety with Critique](https://arxiv.org/pdf/2407.17075v3)** | 2024-08-14 |  |
| **[Less Manual Work for Safety Engineers: Towards an Automated Safety Reasoning with Safety Patterns](https://arxiv.org/pdf/2009.10251v1)** | 2020-09-23 | <details><summary>In Pr...</summary><p>In Proceedings ICLP 2020, arXiv:2009.09158</p></details> |
| **[Trust & Safety of LLMs and LLMs in Trust & Safety](https://arxiv.org/pdf/2412.02113v2)** | 2025-07-01 | 11 pages |
| **[Safety Cases: A Scalable Approach to Frontier AI Safety](https://arxiv.org/pdf/2503.04744v1)** | 2025-03-10 | <details><summary>18 pa...</summary><p>18 pages, 2 figures, 3 tables</p></details> |
| **[Safety Compliance: Rethinking LLM Safety Reasoning through the Lens of Compliance](https://arxiv.org/pdf/2509.22250v1)** | 2025-09-29 |  |

