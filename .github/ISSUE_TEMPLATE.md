---
title: Latest 5 Papers - October 10, 2025
labels: documentation
---
**Please check the [Github](https://github.com/dingyue772/DailyArxiv) page for a better reading experience and more papers.**

## Hallucination
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Distributional Semantics Tracing: A Framework for Explaining Hallucinations in Large Language Models](http://arxiv.org/abs/2510.06107v2)** | 2025-10-08 |  |
| **[Efficient High-Resolution Image Editing with Hallucination-Aware Loss and Adaptive Tiling](http://arxiv.org/abs/2510.06295v1)** | 2025-10-07 | <details><summary>Prepr...</summary><p>Preprint. Under review</p></details> |
| **[ChainMPQ: Interleaved Text-Image Reasoning Chains for Mitigating Relation Hallucinations](http://arxiv.org/abs/2510.06292v1)** | 2025-10-07 |  |
| **[Mitigating Diffusion Model Hallucinations with Dynamic Guidance](http://arxiv.org/abs/2510.05356v1)** | 2025-10-06 |  |
| **[The Geometry of Truth: Layer-wise Semantic Dynamics for Hallucination Detection in Large Language Models](http://arxiv.org/abs/2510.04933v1)** | 2025-10-06 | <details><summary>Comme...</summary><p>Comments: 14 pages, 14 figures, 5 tables. Code available at: https://github.com/sirraya-tech/Sirraya_LSD_Code</p></details> |

## Safety
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[SaFeR-VLM: Toward Safety-aware Fine-grained Reasoning in Multimodal Models](http://arxiv.org/abs/2510.06871v2)** | 2025-10-09 |  |
| **[Decentralized CBF-based Safety Filters for Collision Avoidance of Cooperative Missile Systems with Input Constraints](http://arxiv.org/abs/2510.06846v1)** | 2025-10-08 | 7 pages, 5 figures |
| **[What You Don't Know Can Hurt You: How Well do Latent Safety Filters Understand Partially Observable Safety Constraints?](http://arxiv.org/abs/2510.06492v1)** | 2025-10-07 | 8 tables 6 figures |
| **[R3R: Decentralized Multi-Agent Collision Avoidance with Infinite-Horizon Safety](http://arxiv.org/abs/2510.06436v1)** | 2025-10-07 | <details><summary>8 pag...</summary><p>8 pages, LaTeX; submitted to the American Control Conference (ACC) 2026</p></details> |
| **[Refusal Falls off a Cliff: How Safety Alignment Fails in Reasoning?](http://arxiv.org/abs/2510.06036v1)** | 2025-10-07 |  |

