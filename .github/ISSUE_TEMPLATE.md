---
title: Latest 5 Papers - October 15, 2025
labels: documentation
---
**Please check the [Github](https://github.com/dingyue772/DailyArxiv) page for a better reading experience and more papers.**

## Hallucination
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Hallucination Detection via Internal States and Structured Reasoning Consistency in Large Language Models](http://arxiv.org/abs/2510.11529v1)** | 2025-10-13 |  |
| **[Trustworthy Retrosynthesis: Eliminating Hallucinations with a Diverse Ensemble of Reaction Scorers](http://arxiv.org/abs/2510.10645v1)** | 2025-10-12 |  |
| **[Detecting Hallucinations in Authentic LLM-Human Interactions](http://arxiv.org/abs/2510.10539v1)** | 2025-10-12 |  |
| **[When Images Speak Louder: Mitigating Language Bias-induced Hallucinations in VLMs through Cross-Modal Guidance](http://arxiv.org/abs/2510.10466v1)** | 2025-10-12 |  |
| **[Mitigating Hallucination in Multimodal Reasoning via Functional Attention Control](http://arxiv.org/abs/2510.10285v1)** | 2025-10-11 | preprint |

## Safety
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Bag of Tricks for Subverting Reasoning-based Safety Guardrails](http://arxiv.org/abs/2510.11570v1)** | 2025-10-13 | <details><summary>OpenA...</summary><p>OpenAI Red-teaming Challenge Winner and Oral Presentation</p></details> |
| **[AI Alignment Strategies from a Risk Perspective: Independent Safety Mechanisms or Shared Failures?](http://arxiv.org/abs/2510.11235v1)** | 2025-10-13 | under review |
| **[DeepResearchGuard: Deep Research with Open-Domain Evaluation and Multi-Stage Guardrails for Safety](http://arxiv.org/abs/2510.10994v1)** | 2025-10-13 |  |
| **[The Irrational Machine: Neurosis and the Limits of Algorithmic Safety](http://arxiv.org/abs/2510.10823v1)** | 2025-10-12 | <details><summary>41 pa...</summary><p>41 pages, 17 figures, 5 tables</p></details> |
| **[When Openness Fails: Lessons from System Safety for Assessing Openness in AI](http://arxiv.org/abs/2510.10732v1)** | 2025-10-12 | <details><summary>Accep...</summary><p>Accepted to Symposium on Model Accountability, Sustainability and Healthcare (SMASH) 2025</p></details> |

