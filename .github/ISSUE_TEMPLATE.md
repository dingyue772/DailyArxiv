---
title: Latest 5 Papers - September 03, 2025
labels: documentation
---
**Please check the [Github](https://github.com/dingyue772/DailyArxiv) page for a better reading experience and more papers.**

## Hallucination
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding](http://arxiv.org/abs/2508.21496v1)** | 2025-08-29 |  |
| **[Addressing accuracy and hallucination of LLMs in Alzheimer's disease research through knowledge graphs](http://arxiv.org/abs/2508.21238v1)** | 2025-08-28 |  |
| **[Decoding Memories: An Efficient Pipeline for Self-Consistency Hallucination Detection](http://arxiv.org/abs/2508.21228v1)** | 2025-08-28 | <details><summary>14 pa...</summary><p>14 pages, under review</p></details> |
| **[Mitigating Hallucinations in Multimodal LLMs via Object-aware Preference Optimization](http://arxiv.org/abs/2508.20181v1)** | 2025-08-27 | BMVC 2025 |
| **[GLSim: Detecting Object Hallucinations in LVLMs via Global-Local Similarity](http://arxiv.org/abs/2508.19972v1)** | 2025-08-27 |  |

## Safety
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Improving Aviation Safety Analysis: Automated HFACS Classification Using Reinforcement Learning with Group Relative Policy Optimization](http://arxiv.org/abs/2508.21201v1)** | 2025-08-28 |  |
| **[When technology is not enough: Insights from a pilot cybersecurity culture assessment in a safety-critical industrial organisation](http://arxiv.org/abs/2508.20811v1)** | 2025-08-28 | <details><summary>*Grou...</summary><p>*Group Research and Development, DNV, 1363 H{\o}vik, Norway, {\dag}Safety Risk Nordic, DNV, 1363 H{\o}vik, Norway</p></details> |
| **[Turning the Spell Around: Lightweight Alignment Amplification via Rank-One Safety Injection](http://arxiv.org/abs/2508.20766v1)** | 2025-08-28 | Under Review |
| **[From Law to Gherkin: A Human-Centred Quasi-Experiment on the Quality of LLM-Generated Behavioural Specifications from Food-Safety Regulations](http://arxiv.org/abs/2508.20744v1)** | 2025-08-28 |  |
| **[Governable AI: Provable Safety Under Extreme Threat Models](http://arxiv.org/abs/2508.20411v1)** | 2025-08-28 |  |

