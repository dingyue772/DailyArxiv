---
title: Latest 5 Papers - September 30, 2025
labels: documentation
---
**Please check the [Github](https://github.com/dingyue772/DailyArxiv) page for a better reading experience and more papers.**

## Hallucination
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Fine-Grained Detection of Context-Grounded Hallucinations Using LLMs](http://arxiv.org/abs/2509.22582v2)** | 2025-09-29 |  |
| **[Beyond Textual Context: Structural Graph Encoding with Adaptive Space Alignment to alleviate the hallucination of LLMs](http://arxiv.org/abs/2509.22251v1)** | 2025-09-26 | 11 pages, 5 figures |
| **[Library Hallucinations in LLMs: Risk Analysis Grounded in Developer Queries](http://arxiv.org/abs/2509.22202v1)** | 2025-09-26 | 23 pages, 5 tables |
| **[Black-Box Hallucination Detection via Consistency Under the Uncertain Expression](http://arxiv.org/abs/2509.21999v1)** | 2025-09-26 |  |
| **[Exposing Hallucinations To Suppress Them: VLMs Representation Editing With Generative Anchors](http://arxiv.org/abs/2509.21997v1)** | 2025-09-26 |  |

## Safety
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Closing the Safety Gap: Surgical Concept Erasure in Visual Autoregressive Models](http://arxiv.org/abs/2509.22400v1)** | 2025-09-26 |  |
| **[Safety Compliance: Rethinking LLM Safety Reasoning through the Lens of Compliance](http://arxiv.org/abs/2509.22250v1)** | 2025-09-26 |  |
| **[The Rogue Scalpel: Activation Steering Compromises LLM Safety](http://arxiv.org/abs/2509.22067v1)** | 2025-09-26 |  |
| **[Taxonomy of Comprehensive Safety for Clinical Agents](http://arxiv.org/abs/2509.22041v2)** | 2025-09-29 | EMNLP 2025 Industry |
| **[Benchmarking MLLM-based Web Understanding: Reasoning, Robustness and Safety](http://arxiv.org/abs/2509.21782v1)** | 2025-09-26 |  |

