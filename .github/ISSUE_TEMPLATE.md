---
title: Latest 5 Papers - March 16, 2025
labels: documentation
---
**Please check the [Github](https://github.com/dingyue772/DailyArxiv) page for a better reading experience and more papers.**

## Hallucination
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[TruthPrInt: Mitigating LVLM Object Hallucination Via Latent Truthful-Guided Pre-Intervention](http://arxiv.org/abs/2503.10602v1)** | 2025-03-13 | <details><summary>15 pa...</summary><p>15 pages, 9 figures, the first two authors contributed equally</p></details> |
| **[Through the Magnifying Glass: Adaptive Perception Magnification for Hallucination-Free VLM Decoding](http://arxiv.org/abs/2503.10183v1)** | 2025-03-13 | <details><summary>19 pa...</summary><p>19 pages, 5 figures, 9 tables</p></details> |
| **[Is LLMs Hallucination Usable? LLM-based Negative Reasoning for Fake News Detection](http://arxiv.org/abs/2503.09153v1)** | 2025-03-12 | <details><summary>9 pag...</summary><p>9 pages, 12 figures, conference</p></details> |
| **[Gradient-guided Attention Map Editing: Towards Efficient Contextual Hallucination Mitigation](http://arxiv.org/abs/2503.08963v1)** | 2025-03-11 | <details><summary>Accep...</summary><p>Accepted as Finding of NAACL 2025</p></details> |
| **[Attention Reallocation: Towards Zero-cost and Controllable Hallucination Mitigation of MLLMs](http://arxiv.org/abs/2503.08342v2)** | 2025-03-12 |  |

## MLLM
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[CINEMA: Coherent Multi-Subject Video Generation via MLLM-Based Guidance](http://arxiv.org/abs/2503.10391v1)** | 2025-03-13 |  |
| **[LVAgent: Long Video Understanding by Multi-Round Dynamical Collaboration of MLLM Agents](http://arxiv.org/abs/2503.10200v1)** | 2025-03-13 |  |
| **[Information Density Principle for MLLM Benchmarks](http://arxiv.org/abs/2503.10079v1)** | 2025-03-13 |  |
| **[UVE: Are MLLMs Unified Evaluators for AI-Generated Videos?](http://arxiv.org/abs/2503.09949v1)** | 2025-03-13 |  |
| **[Exo2Ego: Exocentric Knowledge Guided MLLM for Egocentric Video Understanding](http://arxiv.org/abs/2503.09143v1)** | 2025-03-12 | <details><summary>Proje...</summary><p>Project: https://egovisiongroup.github.io/Exo2Ego.github.io/</p></details> |

## Reasoning
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[GoT: Unleashing Reasoning Capability of Multimodal Large Language Model for Visual Generation and Editing](http://arxiv.org/abs/2503.10639v1)** | 2025-03-13 | <details><summary>Datas...</summary><p>Dataset and models are released in https://github.com/rongyaofang/GoT</p></details> |
| **[SciVerse: Unveiling the Knowledge Comprehension and Visual Reasoning of LMMs on Multi-modal Scientific Problems](http://arxiv.org/abs/2503.10627v1)** | 2025-03-13 | <details><summary>Initi...</summary><p>Initially released in September 2024. Project page: https://sciverse-cuhk.github.io</p></details> |
| **[DriveLMM-o1: A Step-by-Step Reasoning Dataset and Large Multimodal Model for Driving Scenario Understanding](http://arxiv.org/abs/2503.10621v1)** | 2025-03-13 | <details><summary>8 pag...</summary><p>8 pages, 4 figures, 3 tables, github: https://github.com/ayesha-ishaq/DriveLMM-o1</p></details> |
| **[R1-Onevision: Advancing Generalized Multimodal Reasoning through Cross-Modal Formalization](http://arxiv.org/abs/2503.10615v1)** | 2025-03-13 | <details><summary>Code ...</summary><p>Code and Model: https://github.com/Fancy-MLLM/R1-onevision</p></details> |
| **[Unveiling the Mathematical Reasoning in DeepSeek Models: A Comparative Study of Large Language Models](http://arxiv.org/abs/2503.10573v1)** | 2025-03-13 |  |

## Reward Model
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[VisualPRM: An Effective Process Reward Model for Multimodal Reasoning](http://arxiv.org/abs/2503.10291v1)** | 2025-03-13 |  |
| **[Policy Teaching via Data Poisoning in Learning from Human Preferences](http://arxiv.org/abs/2503.10228v1)** | 2025-03-13 | In AISTATS 2025 |
| **[Representation-based Reward Modeling for Efficient Safety Alignment of Large Language Model](http://arxiv.org/abs/2503.10093v1)** | 2025-03-13 |  |
| **[PluralLLM: Pluralistic Alignment in LLMs via Federated Learning](http://arxiv.org/abs/2503.09925v1)** | 2025-03-13 |  |
| **[RewardSDS: Aligning Score Distillation via Reward-Weighted Sampling](http://arxiv.org/abs/2503.09601v2)** | 2025-03-13 |  |

