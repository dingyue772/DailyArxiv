---
title: Latest 5 Papers - August 19, 2025
labels: documentation
---
**Please check the [Github](https://github.com/dingyue772/DailyArxiv) page for a better reading experience and more papers.**

## Hallucination
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[EGOILLUSION: Benchmarking Hallucinations in Egocentric Video Understanding](http://arxiv.org/abs/2508.12687v1)** | 2025-08-18 |  |
| **[Mitigating Hallucinations in Large Language Models via Causal Reasoning](http://arxiv.org/abs/2508.12495v1)** | 2025-08-17 |  |
| **[Hallucination in LLM-Based Code Generation: An Automotive Case Study](http://arxiv.org/abs/2508.11257v1)** | 2025-08-15 |  |
| **[MRFD: Multi-Region Fusion Decoding with Self-Consistency for Mitigating Hallucinations in LVLMs](http://arxiv.org/abs/2508.10264v1)** | 2025-08-14 |  |
| **[Prompt-Response Semantic Divergence Metrics for Faithfulness Hallucination and Misalignment Detection in Large Language Models](http://arxiv.org/abs/2508.10192v1)** | 2025-08-13 | 24 pages, 3 figures |

## Safety
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[FuSaR: A Fuzzification-Based Method for LRM Safety-Reasoning Balance](http://arxiv.org/abs/2508.12897v1)** | 2025-08-18 | 14pages, 3 figures |
| **[PFD or PDF: Rethinking the Probability of Failure in Mitigation Safety Functions](http://arxiv.org/abs/2508.12814v1)** | 2025-08-18 |  |
| **[LinguaSafe: A Comprehensive Multilingual Safety Benchmark for Large Language Models](http://arxiv.org/abs/2508.12733v1)** | 2025-08-18 | 7pages, 5 figures |
| **[Rethinking Safety in LLM Fine-tuning: An Optimization Perspective](http://arxiv.org/abs/2508.12531v1)** | 2025-08-17 |  |
| **[SIGN: Safety-Aware Image-Goal Navigation for Autonomous Drones via Reinforcement Learning](http://arxiv.org/abs/2508.12394v1)** | 2025-08-17 |  |

